// Copyright 2025 The contributors of Goinfer.
// This file is part of Goinfer, a LLM proxy under the MIT License.
// SPDX-License-Identifier: MIT

package conf

import (
	"bytes"
	"maps"
	"slices"
	"strings"
)

// LlamaINI is the llama.cpp config filename.
const LlamaINI = "llama.ini"

// WriteLlamaINI insert the header and writes the llama.cpp configuration for `--models-preset ./llama.ini`.
func WriteLlamaINI(yml []byte) error {
	header := `# DO NOT EDIT - This file is generated by Goinfer.
#
# llama.cpp configurations using Model Presets:
#
#     llama-server --models-preset ./llama.ini
#
# Each section in this file defines a new preset.
# Keys within a section correspond to command-line arguments (without leading dashes).
# For example, the argument --n-gpu-layer 123 is written as n-gpu-layer = 123.
# Short argument forms (e.g., c, ngl) and environment variable names (e.g., LLAMA_ARG_N_GPU_LAYERS) are also supported as keys.
#
# Doc: https://github.com/ggml-org/llama.cpp/blob/master/tools/server/README.md#model-presets
`
	return writeWithHeader(LlamaINI, header, yml)
}

// GenLlamaINI generates the llama.cpp configuration for `--models-preset ./llama.ini`.
func (cfg *Cfg) GenLlamaINI() []byte {
	out := bytes.NewBufferString(`
version = 1
`)
	// For each model, set two model settings:
	// 1. for the OpenAI endpoints
	// 2. for the /completion endpoint (prefix with A_ and hide the model)
	info := cfg.getInfo()
	for _, model := range slices.Sorted(maps.Keys(info)) {
		mi := info[model]
		genModel(out, model, mi.Path, mi.Flags)
		genModel(out, model+PLUS_A, mi.Path, cfg.Llama.Goinfer+" "+mi.Flags)
	}

	return out.Bytes()
}

// Add the model settings within the llama-swap configuration.
func genModel(out *bytes.Buffer, name, path, flags string) {
	out.WriteString(`
[` + name + `]
model = ` + path)

	// wroteKey is the state of the state machine
	wroteKey := false

	for arg := range strings.FieldsSeq(flags) {
		arg = strings.Trim(arg, "'")
		wroteKey = genParam(out, arg, wroteKey)
	}

	if wroteKey {
		out.WriteString(" true\n")
	} else {
		out.WriteByte('\n')
	}
}

// Add the model settings within the llama-swap configuration.
func genParam(out *bytes.Buffer, arg string, wroteKey bool) bool {
	if arg == "" || arg[0] != '-' {
		out.WriteByte(' ')
		out.WriteString(arg)
		return false
	}

	if wroteKey {
		out.WriteString(" true")
	}

	out.WriteByte('\n')

	// write the parameter without the leading dash(es)
	i := 1
	if len(arg) > 2 && arg[1] == '-' {
		i = 2
	}
	out.WriteString(arg[i:])

	out.WriteByte(' ')
	out.WriteByte('=')
	return true
}
