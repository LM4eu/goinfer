# Configure the OpenAI API

To enable this API, ensure an API key and a port is set for the `openai` in `goinfer.yml`:

```yaml
server:
  api_key:
    openai:  your_secret_key_here
  listen:
    :2222: openai
```

## (OBSOLETE DEPRECATED TODO) Parameters

- `template` *string*: the template to use for system and user roles, see below

## (OBSOLETE DEPRECATED TODO) Template

The template maps the `messages` payload for the `/v1/chat/completions` endpoint. Example payload:

```js
{
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "this is the prompt content"
    }
  ]
}
```

For this template:

    {system}\n\n### Instruction: {prompt}\n\n### Response:

It will create this final prompt for Llama.cpp:

    You are a helpful assistant.

    ### Instruction: this is the prompt content

    ### Response:
