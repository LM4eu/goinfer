# Load a model

Load a model into the server memory:

- `/model/load` *POST*: payload:
  - `model` *string* **required**: the model name to load
  - `ctx` *int*: context window size, default *1024*
  - `embeddings` *boolean*: use embeddings, default *false*
  - `gpuLayers` *int*: number of layers to run on GPU, default *0*

Example payload:

```js
{
  "model": "orca-mini-3b.gguf.q8_0"
}
// or
{
  "model": "orca-mini-3b.gguf.q8_0",
  "ctx": 2048
}
```

The response will be a `204` status code when the model is loaded

## Example

```bash
curl -X POST -H "Content-Type: application/json" -d \
'{"model": "orca-mini-3b.gguf.q8_0"}' http://localhost:5143/model/load
```

## Unload a model

To unload a model use the `/model/unload` *GET* endpoint