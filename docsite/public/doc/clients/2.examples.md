# Client examples

## Javascript

- [Streaming response](https://github.com/LM4eu/goinfer/blob/main/examples/js/sse/sse.mjs): query the server and
get a streaming response using the server sent events
- [OpenAI API](https://github.com/LM4eu/goinfer/blob/main/examples/js/openai_api/sse.mjs): use the OpenAI API. Other
example: using the [ChatGPT Node library](https://github.com/LM4eu/goinfer/blob/main/examples/js/openai_api/chatgpt_lib.mjs)
- [Prompt templates](https://github.com/LM4eu/goinfer/blob/main/examples/js/template/model_template.js): example on how to
use the [ModPrompt](https://github.com/synw/modprompt) library and the models state info on server to automate templating
- [Goinfer client library](https://github.com/LM4eu/goinfer/blob/main/examples/js/template/goinfer_lib.ts): use the 
[@goinfer/api](https://github.com/LM4eu/goinfer-js) library

## Python

- [Streaming response](https://github.com/LM4eu/goinfer/blob/main/examples/python/sse.py): query the server and
get a streaming response using the server sent events
- [Summarize text](https://github.com/LM4eu/goinfer/blob/main/examples/python/summarize.py): fetch an article and
summarize it
- [Extract relevant information](https://github.com/LM4eu/goinfer/blob/main/examples/python/one_shot.py): fetch some
news headlines and extract given topics using a one shot prompt

